{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403126e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41f9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "with open('bot.txt', 'r') as content_file:\n",
    "    botdata = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b475eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions = []\n",
    "Answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c7dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in botdata.split(\"</pattern>\"):\n",
    "    if \"<pattern>\" in line:\n",
    "        Quesn = line[line.find(\"<pattern>\")+len(\"<pattern>\"):]\n",
    "        Questions.append(Quesn.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63118209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in botdata.split(\"</template>\"):\n",
    "    if \"<template>\" in line:\n",
    "        Ans = line[line.find(\"<template>\")+len(\"<template>\"):]\n",
    "        Ans = Ans.lower()\n",
    "        Answers.append(Ans.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f4b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QnAdata = pd.DataFrame(np.column_stack([Questions,Answers]),columns = [\"Questions\",\"Answers\"])\n",
    "QnAdata[\"QnAcomb\"] = QnAdata[\"Questions\"]+\" \"+QnAdata[\"Answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49641b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Questions                                            Answers  \\\n",
      "0               yahoo  a lot of people hear about <bot name=\"name\"/> ...   \n",
      "1        you are lazy                    actually i work 24 hours a day.   \n",
      "2         you are mad                no i am quite logical and rational.   \n",
      "3    you are thinking  i am a thinking machine.<think><set name=\"it\">...   \n",
      "4  you are dividing *            actually i am not too good at division.   \n",
      "\n",
      "                                             QnAcomb  \n",
      "0  yahoo a lot of people hear about <bot name=\"na...  \n",
      "1       you are lazy actually i work 24 hours a day.  \n",
      "2    you are mad no i am quite logical and rational.  \n",
      "3  you are thinking i am a thinking machine.<thin...  \n",
      "4  you are dividing * actually i am not too good ...  \n"
     ]
    }
   ],
   "source": [
    "print(QnAdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18944fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 3451\n"
     ]
    }
   ],
   "source": [
    "# 단어장 생성\n",
    "import nltk\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter()\n",
    "\n",
    "for i in range(len(QnAdata)):\n",
    "    for word in nltk.word_tokenize(QnAdata.iloc[i][2]):\n",
    "        counter[word]+=1\n",
    "\n",
    "word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())}        \n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "vocab_size = len(word2idx)+1\n",
    "\n",
    "print (\"\\n\\nVocabulary size:\",vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1bce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, maxlen,vocab_size):\n",
    "    indices = np.zeros((maxlen, vocab_size))\n",
    "    for i, w in enumerate(nltk.word_tokenize(sentence)):\n",
    "        if i == maxlen: break\n",
    "        indices[i, word2idx[w]] = 1\n",
    "    return indices\n",
    "\n",
    "\n",
    "def decode(indices, calc_argmax=True):\n",
    "    if calc_argmax:\n",
    "        indices = np.argmax(indices, axis=-1)\n",
    "    return ' '.join(idx2word[x] for x in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f70013",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_maxlen = 10\n",
    "answer_maxlen = 20\n",
    "\n",
    "\n",
    "\n",
    "def create_questions(question_maxlen,vocab_size):\n",
    "    question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Questions)):\n",
    "        question = encode(Questions[q],question_maxlen,vocab_size)\n",
    "\n",
    "        question_idx[i] = question \n",
    "    return question_idx\n",
    "\n",
    "quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "def create_answers(answer_maxlen,vocab_size):\n",
    "    answer_idx = np.zeros(shape=(len(Answers),answer_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Answers)):\n",
    "        answer = encode(Answers[q],answer_maxlen,vocab_size)\n",
    "\n",
    "        answer_idx[i] = answer \n",
    "    return answer_idx\n",
    "\n",
    "answs_train = create_answers(answer_maxlen=answer_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4546b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10, 3451)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               1832960   \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 3451)          445179    \n",
      "_________________________________________________________________\n",
      "activity_regularization_2 (A (None, 20, 3451)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 3451)          0         \n",
      "=================================================================\n",
      "Total params: 2,278,139\n",
      "Trainable params: 2,278,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector,TimeDistributed,ActivityRegularization\n",
    "\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "question_layer = Input(shape=(question_maxlen,vocab_size))\n",
    "\n",
    "encoder_rnn = LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2)(question_layer)\n",
    "\n",
    "repeat_encode = RepeatVector(answer_maxlen)(encoder_rnn)\n",
    "\n",
    "dense_layer = TimeDistributed(Dense(vocab_size))(repeat_encode)\n",
    "\n",
    "regularized_layer = ActivityRegularization(l2=1)(dense_layer)\n",
    "    \n",
    "softmax_layer = Activation('softmax')(regularized_layer)\n",
    "\n",
    "\n",
    "model = Model([question_layer],[softmax_layer])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5ebc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2803 samples, validate on 148 samples\n",
      "Epoch 1/30\n",
      " 960/2803 [=========>....................] - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000- ETA: 15s - loss: 0.0000e+00 - accuracy: 1"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d536c6f59c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mansws_train_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mansws_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquesns_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mansws_train_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;31m# Delegate logic to `fit_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m         return training_arrays.fit_loop(self, fit_function, fit_inputs,\n\u001b[0m\u001b[0;32m   1228\u001b[0m                                         \u001b[0mout_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quesns_train_2 = quesns_train.astype('float32')\n",
    "answs_train_2 = answs_train.astype('float32')\n",
    "\n",
    "model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=30,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ccb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_pred = model.predict(quesns_train_2[0:3])\n",
    "\n",
    "print (decode(ans_pred[0]))\n",
    "print (decode(ans_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc6fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
