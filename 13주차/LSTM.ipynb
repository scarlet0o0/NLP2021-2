{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403126e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41f9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "with open('bot.txt', 'r') as content_file:\n",
    "    botdata = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b475eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions = []\n",
    "Answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c7dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in botdata.split(\"</pattern>\"):\n",
    "    if \"<pattern>\" in line:\n",
    "        Quesn = line[line.find(\"<pattern>\")+len(\"<pattern>\"):]\n",
    "        Questions.append(Quesn.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63118209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in botdata.split(\"</template>\"):\n",
    "    if \"<template>\" in line:\n",
    "        Ans = line[line.find(\"<template>\")+len(\"<template>\"):]\n",
    "        Ans = Ans.lower()\n",
    "        Answers.append(Ans.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f4b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QnAdata = pd.DataFrame(np.column_stack([Questions,Answers]),columns = [\"Questions\",\"Answers\"])\n",
    "QnAdata[\"QnAcomb\"] = QnAdata[\"Questions\"]+\" \"+QnAdata[\"Answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49641b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Questions                                            Answers  \\\n",
      "0               yahoo  a lot of people hear about <bot name=\"name\"/> ...   \n",
      "1        you are lazy                    actually i work 24 hours a day.   \n",
      "2         you are mad                no i am quite logical and rational.   \n",
      "3    you are thinking  i am a thinking machine.<think><set name=\"it\">...   \n",
      "4  you are dividing *            actually i am not too good at division.   \n",
      "\n",
      "                                             QnAcomb  \n",
      "0  yahoo a lot of people hear about <bot name=\"na...  \n",
      "1       you are lazy actually i work 24 hours a day.  \n",
      "2    you are mad no i am quite logical and rational.  \n",
      "3  you are thinking i am a thinking machine.<thin...  \n",
      "4  you are dividing * actually i am not too good ...  \n"
     ]
    }
   ],
   "source": [
    "print(QnAdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18944fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 3451\n"
     ]
    }
   ],
   "source": [
    "# 단어장 생성\n",
    "import nltk\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter()\n",
    "\n",
    "for i in range(len(QnAdata)):\n",
    "    for word in nltk.word_tokenize(QnAdata.iloc[i][2]):\n",
    "        counter[word]+=1\n",
    "\n",
    "word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())}        \n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "vocab_size = len(word2idx)+1\n",
    "\n",
    "print (\"\\n\\nVocabulary size:\",vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1bce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, maxlen,vocab_size):\n",
    "    indices = np.zeros((maxlen, vocab_size))\n",
    "    for i, w in enumerate(nltk.word_tokenize(sentence)):\n",
    "        if i == maxlen: break\n",
    "        indices[i, word2idx[w]] = 1\n",
    "    return indices\n",
    "\n",
    "\n",
    "def decode(indices, calc_argmax=True):\n",
    "    if calc_argmax:\n",
    "        indices = np.argmax(indices, axis=-1)\n",
    "    return ' '.join(idx2word[x] for x in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f70013",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_maxlen = 10\n",
    "answer_maxlen = 20\n",
    "\n",
    "\n",
    "\n",
    "def create_questions(question_maxlen,vocab_size):\n",
    "    question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Questions)):\n",
    "        question = encode(Questions[q],question_maxlen,vocab_size)\n",
    "\n",
    "        question_idx[i] = question \n",
    "    return question_idx\n",
    "\n",
    "quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "def create_answers(answer_maxlen,vocab_size):\n",
    "    answer_idx = np.zeros(shape=(len(Answers),answer_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Answers)):\n",
    "        answer = encode(Answers[q],answer_maxlen,vocab_size)\n",
    "\n",
    "        answer_idx[i] = answer \n",
    "    return answer_idx\n",
    "\n",
    "answs_train = create_answers(answer_maxlen=answer_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4546b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 3451)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               1832960   \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 3451)          445179    \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 20, 3451)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 3451)          0         \n",
      "=================================================================\n",
      "Total params: 2,278,139\n",
      "Trainable params: 2,278,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector,TimeDistributed,ActivityRegularization\n",
    "\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "question_layer = Input(shape=(question_maxlen,vocab_size))\n",
    "\n",
    "encoder_rnn = LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2)(question_layer)\n",
    "\n",
    "repeat_encode = RepeatVector(answer_maxlen)(encoder_rnn)\n",
    "\n",
    "dense_layer = TimeDistributed(Dense(vocab_size))(repeat_encode)\n",
    "\n",
    "regularized_layer = ActivityRegularization(l2=1)(dense_layer)\n",
    "    \n",
    "softmax_layer = Activation('softmax')(regularized_layer)\n",
    "\n",
    "\n",
    "model = Model([question_layer],[softmax_layer])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5ebc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2803 samples, validate on 148 samples\n",
      "Epoch 1/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 2/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 3/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 4/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 5/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 6/30\n",
      "2803/2803 [==============================] - 21s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 7/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 8/30\n",
      "2803/2803 [==============================] - 24s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 9/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 10/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 11/30\n",
      "2803/2803 [==============================] - 21s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 12/30\n",
      "2803/2803 [==============================] - 25s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 13/30\n",
      "2803/2803 [==============================] - 24s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 14/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 15/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 16/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 17/30\n",
      "2803/2803 [==============================] - 24s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 18/30\n",
      "2803/2803 [==============================] - 21s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 19/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 20/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 21/30\n",
      "2803/2803 [==============================] - 24s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 22/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 23/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 24/30\n",
      "2803/2803 [==============================] - 21s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 25/30\n",
      "2803/2803 [==============================] - 25s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 26/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 27/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 28/30\n",
      "2803/2803 [==============================] - 21s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 29/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n",
      "Epoch 30/30\n",
      "2803/2803 [==============================] - 25s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23329c1ad30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quesns_train_2 = quesns_train.astype('float32')\n",
    "answs_train_2 = answs_train.astype('float32')\n",
    "\n",
    "model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=30,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3ccb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "ans_pred = model.predict(quesns_train_2[0:3])\n",
    "\n",
    "print (decode(ans_pred[0]))\n",
    "print (decode(ans_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc6fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
