{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36ef890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#합성곱망 CNN1D를 이용한 OIIMDB감정분류\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d09f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "17473536/17464789 [==============================] - 2s 0us/step\n",
      "25000 train observations\n",
      "25000 test observations\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 설정:\n",
    "max_features = 6000 # 추출할 단어의 수\n",
    "max_length = 400 #각 문장의 최대 길이\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), 'train observations')\n",
    "print(len(x_test), 'test observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1386c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 단어 대 숫자 매핑 생성 \n",
    "wind = imdb.get_word_index()\n",
    "revind = dict((v,k) for k,v in wind.items())\n",
    "print (x_train[0])\n",
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89e30f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought and but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 역 매핑된 Dictionaryfmf 사용하여 디코딩 수행\n",
    "def decode(sent_list):\n",
    "    new_words = []\n",
    "    for i in sent_list:\n",
    "        new_words.append(revind[i])\n",
    "    comb_words = \" \".join(new_words)\n",
    "    return comb_words  \n",
    "\n",
    "print (decode(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587f6578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "# 효율적인 연산을 위한 패드 배열\n",
    "#각문장 길이를 일정한 MAX_length로 맞춤\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f67cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 아키텍쳐 파라미터\n",
    "batch_size = 32\n",
    "embedding_dims = 60\n",
    "num_kernels = 260\n",
    "kernel_size = 3\n",
    "hidden_dims = 300\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4ff249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 60)           360000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 60)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 260)          47060     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 260)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               78300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 485,661\n",
      "Trainable params: 485,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 모델 구축\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,embedding_dims,input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(num_kernels,kernel_size,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a1f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 84s 131ms/step - loss: 0.4577 - accuracy: 0.7616 - val_loss: 0.2908 - val_accuracy: 0.8784\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.2443 - accuracy: 0.9032 - val_loss: 0.2650 - val_accuracy: 0.8922\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.1614 - accuracy: 0.9401 - val_loss: 0.2726 - val_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202422747f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26199ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_predclass = np.round(model.predict(x_train)).astype(int)\n",
    "y_test_predclass = np.round(model.predict(x_test)).astype(int)\n",
    "\n",
    "y_train_predclass.shape = y_train.shape\n",
    "y_test_predclass.shape = y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c762dbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2e4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ffaf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c029cff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2394e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CNN 1D  - Train accuracy: 0.966\n",
      "\n",
      "CNN 1D of Training data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     12500\n",
      "           1       0.96      0.97      0.97     12500\n",
      "\n",
      "    accuracy                           0.97     25000\n",
      "   macro avg       0.97      0.97      0.97     25000\n",
      "weighted avg       0.97      0.97      0.97     25000\n",
      "\n",
      "\n",
      "CNN 1D - Train Confusion Matrix\n",
      "\n",
      " Predicted      0      1\n",
      "Actuall                \n",
      "0          11972    528\n",
      "1            330  12170\n",
      "\n",
      "CNN 1D  - Test accuracy: 0.888\n",
      "\n",
      "CNN 1D of Test data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89     12500\n",
      "           1       0.87      0.91      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n",
      "\n",
      "CNN 1D - Test Confusion Matrix\n",
      "\n",
      " Predicted      0      1\n",
      "Actuall                \n",
      "0          10881   1619\n",
      "1           1180  11320\n"
     ]
    }
   ],
   "source": [
    "print ((\"\\n\\nCNN 1D  - Train accuracy:\"),(round(accuracy_score(y_train,y_train_predclass),3)))\n",
    "print (\"\\nCNN 1D of Training data\\n\",classification_report(y_train, y_train_predclass))\n",
    "print (\"\\nCNN 1D - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, y_train_predclass,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))      \n",
    "\n",
    "print ((\"\\nCNN 1D  - Test accuracy:\"),(round(accuracy_score(y_test,y_test_predclass),3)))\n",
    "print (\"\\nCNN 1D of Test data\\n\",classification_report(y_test, y_test_predclass))\n",
    "print (\"\\nCNN 1D - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, y_test_predclass,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7994793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
